{"cells":[{"cell_type":"code","source":["# ==============================================================================\n","# SPARK PERFORMANCE TUNING & OPTIMIZATION\n","# ==============================================================================\n","\n","# Shuffle Partitions: Sets the number of partitions to use when shuffling data for \n","# joins or aggregations. 200 is the default, but vital to declare for consistency.\n","spark.conf.set(\"spark.sql.shuffle.partitions\", \"200\")\n","\n","# Adaptive Query Execution (AQE): Enables Spark's ability to re-optimize query \n","# plans at runtime based on the actual statistics of the data being processed.\n","spark.conf.set(\"spark.sql.adaptive.enabled\", \"true\")\n","\n","# Dynamic Partition Coalescing: Allows AQE to merge small partitions together \n","# to reduce overhead when data volume is lower than expected.\n","spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n","\n","# Memory Management: Forces Spark to target 64MB partitions. Smaller sizes are \n","# often better for environments to prevent 'Out of Memory' (OOM) errors.\n","spark.conf.set(\"spark.sql.adaptive.advisoryPartitionSizeInBytes\", \"64mb\") \n","\n","# Skew Join Optimization: Automatically handles 'data skew' where one partition \n","# is much larger than others, preventing a single task from bottlenecking the pipeline.\n","spark.conf.set(\"spark.sql.adaptive.skewJoin.enabled\", \"true\")\n","\n","# Checkpointing: Sets the directory for metadata and state storage. \n","# Used to truncate long lineage chains and improve fault tolerance.\n","spark.sparkContext.setCheckpointDir(\"Files/checkpoints\")\n","\n","print(\"Spark configurations applied!\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"9b8a09ed-c18f-4da2-b607-66d6efb5db58","normalized_state":"finished","queued_time":"2026-02-01T04:09:24.1561601Z","session_start_time":"2026-02-01T04:09:24.157871Z","execution_start_time":"2026-02-01T04:09:40.8274205Z","execution_finish_time":"2026-02-01T04:09:43.6850466Z","parent_msg_id":"75ab61b1-1d35-4074-a8e4-3536a0fc627c"},"text/plain":"StatementMeta(, 9b8a09ed-c18f-4da2-b607-66d6efb5db58, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Spark configurations applied!\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"bc8e47b5-d046-46c2-bc7d-3ddd301df2f1"},{"cell_type":"code","source":["# ==============================================================================\n","# STANDARD LIBRARIES & EXTERNAL DATA TOOLS\n","# ==============================================================================\n","\n","# mssparkutils: Microsoft Fabric utility toolset for file system \n","# management and notebook orchestration.\n","from notebookutils import mssparkutils\n","\n","# Advanced String Functions:\n","# - regexp_replace: Used for complex pattern-based cleaning (e.g., removing special characters).\n","# - lower / initcap: Standardizes casing for names and categories.\n","# - translate: Efficiently replaces specific characters (useful for encoding or accent removal).\n","# - when: Essential for conditional 'if-then-else' logic within Spark columns.\n","from pyspark.sql.functions import col, trim, regexp_replace, lower, initcap, translate, when \n","\n","# F: Standard alias for the full PySpark SQL functions suite.\n","from pyspark.sql import functions as F\n","\n","# Data Science Ecosystem:\n","# - pandas (pd): Used for smaller, local data manipulations or converting to/from Spark.\n","# - numpy (np): Provides support for large, multi-dimensional arrays and high-level math.\n","import pandas as pd\n","import numpy as np"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"9b8a09ed-c18f-4da2-b607-66d6efb5db58","normalized_state":"finished","queued_time":"2026-02-01T04:09:24.363984Z","session_start_time":null,"execution_start_time":"2026-02-01T04:09:43.6884373Z","execution_finish_time":"2026-02-01T04:09:44.5694322Z","parent_msg_id":"92ed83c4-ed3a-484b-b7fd-0a9fb3ce723f"},"text/plain":"StatementMeta(, 9b8a09ed-c18f-4da2-b607-66d6efb5db58, 4, Finished, Available, Finished)"},"metadata":{}}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cec0f50e-246a-4805-95d3-9a7943762c2a"},{"cell_type":"code","source":["# Function to interface with the Spark catalog and retrieve data\n","def extract_table(table_name: str):\n","    \"\"\"\n","    Reads a table from the Spark catalog and loads it into a DataFrame.\n","    \n","    In Microsoft Fabric, this function pulls metadata and data from the \n","    defined Lakehouse tables, supporting both managed and external tables.\n","\n","    Args:\n","        table_name (str): The name of the table to be extracted.\n","                          Example: 'BronzeLakeHouse.dbo.customers'\n","\n","    Returns:\n","        pyspark.sql.dataframe.DataFrame: A Spark DataFrame containing the table data.\n","    \"\"\"\n","\n","    df = spark.read.table(table_name)\n","    \n","    return df"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"9b8a09ed-c18f-4da2-b607-66d6efb5db58","normalized_state":"finished","queued_time":"2026-02-01T04:09:24.8589148Z","session_start_time":null,"execution_start_time":"2026-02-01T04:09:44.5728289Z","execution_finish_time":"2026-02-01T04:09:44.8513304Z","parent_msg_id":"d7460aed-9805-4256-a351-8254eb688398"},"text/plain":"StatementMeta(, 9b8a09ed-c18f-4da2-b607-66d6efb5db58, 5, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d6dc86ea-26f4-4591-bffc-8935f4f83b0e"},{"cell_type":"code","source":["# Function to automate whitespace removal across all string-type data\n","def trim_all_string_cols(df):\n","    \"\"\"\n","    Scans the DataFrame schema to identify all string columns and applies \n","    the trim() function to remove leading and trailing whitespace.\n","    \n","    Args:\n","        df (pyspark.sql.DataFrame): The input DataFrame.\n","        \n","    Returns:\n","        pyspark.sql.DataFrame: DataFrame with all string columns cleaned.\n","    \"\"\"\n","\n","    # Identify string columns: df.dtypes returns a list of (column_name, data_type).\n","    # We filter specifically for 'string' to avoid errors on numeric or date types.\n","    string_columns = [c for c, t in df.dtypes if t == 'string']\n","\n","    # withColumns: Efficiently applies the transformation to multiple columns \n","    # simultaneously using a dictionary comprehension.\n","    df_trimmed = df.withColumns({c: trim(col(c)) for c in string_columns})\n","\n","    return df_trimmed"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"9b8a09ed-c18f-4da2-b607-66d6efb5db58","normalized_state":"finished","queued_time":"2026-02-01T04:09:25.0877413Z","session_start_time":null,"execution_start_time":"2026-02-01T04:09:44.8545953Z","execution_finish_time":"2026-02-01T04:09:45.1575193Z","parent_msg_id":"72a43935-db07-4158-85b8-aa5680d597c4"},"text/plain":"StatementMeta(, 9b8a09ed-c18f-4da2-b607-66d6efb5db58, 6, Finished, Available, Finished)"},"metadata":{}}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5d910dd6-af83-4693-95be-68b0986260c6"},{"cell_type":"code","source":["# Function to standardize city names by removing accents and special characters\n","def clean_geolocation_city(df_geo):\n","\n","    print(\"In clean_geolocation_city ...\")\n","    \n","    # commented old code not efficient (Keep for reference)\n","\n","    # df_cleaned = df_geo.withColumn(\n","    #     \"geolocation_city_clean\",\n","    #     # Step 1: Convert to lowercase\n","    #     lower(F.col(\"geolocation_city\"))\n","    # ).withColumn(\n","    #     \"geolocation_city_clean\",\n","    #     # Step 2: Remove extra whitespaces (leading, trailing, multiple spaces)\n","    #     regexp_replace(trim(F.col(\"geolocation_city_clean\")), \"\\\\s+\", \" \")    \n","    # ).withColumn(\n","    #     \"geolocation_city_clean\",\n","    #     # Step 3: Remove special characters and accents\n","    #     translate(\n","    #         F.col(\"geolocation_city_clean\"),\n","    #         \"áàâãäéèêëíìîïóòôõöúùûüçñ\",\n","    #         \"aaaaaeeeeiiiiooooouuuucn\"\n","    #     )\n","    # ).withColumn(\n","    #     \"geolocation_city_clean\",\n","    #     # Step 4: Remove remaining non-alphanumeric characters (except spaces)\n","    #     regexp_replace(F.col(\"geolocation_city_clean\"), \"[^a-z0-9\\\\s]\", \"\")\n","    # )\n","\n","\n","    # Nested Transformation Logic:\n","    # 1. lower() & trim(): Standardizes casing and removes outer whitespace.\n","    # 2. regexp_replace(..., \"\\\\s+\", \" \"): Collapses multiple internal spaces into one.\n","    # 3. translate(...): Maps accented characters (e.g., 'ã') to plain equivalents ('a').\n","    # 4. regexp_replace(..., \"[^a-z0-9\\\\s]\", \"\"): Removes punctuation/symbols.\n","    cleaned_city = regexp_replace(\n","        translate(\n","            regexp_replace(\n","                trim(lower(F.col(\"geolocation_city\"))),\n","                \"\\\\s+\", \" \"\n","            ),\n","            \"áàâãäéèêëíìîïóòôõöúùûüçñ\",\n","            \"aaaaaeeeeiiiiooooouuuucn\"\n","        ),\n","        \"[^a-z0-9\\\\s]\", \"\"\n","    )    \n","\n","    # Apply the combined expression and replace the original column\n","    df_cleaned = df_geo.withColumn(\"geolocation_city_clean\", cleaned_city)\n","    df_cleaned = df_cleaned.drop(\"geolocation_city\").withColumnRenamed(\"geolocation_city_clean\", \"geolocation_city\")\n","\n","    return df_cleaned"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"state":"finished","livy_statement_state":"available","session_id":"9b8a09ed-c18f-4da2-b607-66d6efb5db58","normalized_state":"finished","queued_time":"2026-02-01T04:09:25.3261053Z","session_start_time":null,"execution_start_time":"2026-02-01T04:09:45.1608235Z","execution_finish_time":"2026-02-01T04:09:45.4769362Z","parent_msg_id":"50ac2822-5845-4f70-9886-ef07dab355da"},"text/plain":"StatementMeta(, 9b8a09ed-c18f-4da2-b607-66d6efb5db58, 7, Finished, Available, Finished)"},"metadata":{}}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"340d32fa-1d3c-4a68-ba8a-6f4386ca1f7e"},{"cell_type":"code","source":["# Function to aggregate spatial coordinates and remove redundancy\n","def group_consolidate_data(df):\n","    \"\"\"\n","    Consolidates geolocation data by grouping on postal and administrative levels.\n","    Calculates the average latitude and longitude for each unique Zip/State/City \n","    combination and ensures the final output is free of duplicate records.\n","\n","    Args:\n","        df (pyspark.sql.DataFrame): The cleaned geolocation DataFrame.\n","\n","    Returns:\n","        pyspark.sql.DataFrame: A summarized DataFrame with one set of coordinates per location.\n","    \"\"\"\n","\n","    print(\"In group_consolidate_data ...\")\n","  \n","    # 1. Spatial Aggregation: Group by hierarchy and calculate the mean coordinates.\n","    # We use mean() to find the geographic center of all entries for a specific zip code.\n","    group_df = df.groupBy(['geolocation_zip_code_prefix', 'geolocation_state', 'geolocation_city']) \\\n","        .agg(\n","            F.mean('geolocation_lat').alias('geolocation_lat'),\n","            F.mean('geolocation_lng').alias('geolocation_lng')\n",")\n","\n","    # 2. De-duplication: Ensures each group result is unique across the dataset.\n","    # Note: Logic to count duplicates is currently disabled but preserved for debugging.\n","    group_df = group_df.dropDuplicates()\n","\n","    return group_df"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":8,"statement_ids":[8],"state":"finished","livy_statement_state":"available","session_id":"9b8a09ed-c18f-4da2-b607-66d6efb5db58","normalized_state":"finished","queued_time":"2026-02-01T04:09:25.5058474Z","session_start_time":null,"execution_start_time":"2026-02-01T04:09:45.4801682Z","execution_finish_time":"2026-02-01T04:09:45.8467738Z","parent_msg_id":"71b058eb-8101-422c-ba4e-e4f65ebcda11"},"text/plain":"StatementMeta(, 9b8a09ed-c18f-4da2-b607-66d6efb5db58, 8, Finished, Available, Finished)"},"metadata":{}}],"execution_count":6,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5c76b6d4-8d9d-432c-8a3e-87dcf202e484"},{"cell_type":"code","source":["# Function to persist the consolidated geolocation data into a Delta Table\n","def load_df_to_delta(df, table_name: str, mode: str = \"overwrite\"):\n","    \"\"\"\n","    Load and saves dataframe data as a Delta Table.\n","    \n","    Args:\n","        df (spark DataFrame): df to be loaded to delta table.\n","        table_name: name of destination table \n","        mode (str): 'overwrite' to replace the table, default.\n","    \"\"\"\n","    print(\"In load_df_to_delta ...\")\n","\n","    try:\n","        # 1. Save as a Delta Table \n","        df.write.format(\"delta\") \\\n","            .mode(mode) \\\n","            .option(\"overwriteSchema\", \"true\") \\\n","            .saveAsTable(table_name)\n","\n","        print(f\"Table '{table_name}' loaded successfully !\")\n","        \n","    except Exception as e:\n","        # Error handling to capture failures such as permissions or path issues\n","        print(f\"Error processing table {table_name}: {str(e)}\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","session_id":"9b8a09ed-c18f-4da2-b607-66d6efb5db58","normalized_state":"finished","queued_time":"2026-02-01T04:09:25.7341029Z","session_start_time":null,"execution_start_time":"2026-02-01T04:09:45.8499129Z","execution_finish_time":"2026-02-01T04:09:46.1622138Z","parent_msg_id":"f1920096-92f7-4e5b-87db-6a70e42680bd"},"text/plain":"StatementMeta(, 9b8a09ed-c18f-4da2-b607-66d6efb5db58, 9, Finished, Available, Finished)"},"metadata":{}}],"execution_count":7,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ff4a38cd-06db-4323-bc09-8c97e2895e7a"},{"cell_type":"code","source":["# Function to perform high-performance uniqueness validation on composite keys\n","def check_records_count(df):\n","    \"\"\"\n","    Audits the DataFrame for duplicates based on the composite key of \n","    Zip Code, State, and City. Uses caching and repartitioning to \n","    optimize performance across multiple count actions.\n","\n","    Args:\n","        df (pyspark.sql.DataFrame): The DataFrame to be audited.\n","    \"\"\"\n","\n","    print(\"In check_records_count ...\")\n","    \n","    # 1. Define the composite key columns: Uniqueness is defined by this triplet.\n","    key_cols = ['geolocation_zip_code_prefix', 'geolocation_state', 'geolocation_city']\n","    \n","    # 2. Optimization: Repartitioning moves identical keys to the same partition.\n","    # .cache() keeps the result in memory, avoiding redundant computation for counts.\n","    df_cached = df.repartition(200, *key_cols).cache()\n","    \n","    # 3. Execution: Calculate total vs. distinct counts.\n","    total_count = df_cached.count()\n","    print(f\"Total count: {total_count}\")\n","    \n","    # Count distinct using the cached data\n","    distinct_count = df_cached.select(key_cols).distinct().count()\n","    print(f\"Distinct count (composite key): {distinct_count}\")\n","    \n","    duplicate_count = total_count - distinct_count\n","    print(f\"Duplicate records: {duplicate_count}\")\n","    \n","    # 4. Investigation: Identify the specific \"hot\" keys causing duplicates.\n","    if duplicate_count > 0:\n","        print(\"\\nRecords to investigate (duplicates based on composite key):\")\n","        duplicates = df_cached.groupBy(key_cols) \\\n","            .count() \\\n","            .filter(F.col(\"count\") > 1) \\\n","            .orderBy(F.desc(\"count\")) \\\n","            .limit(50)  # Limit results\n","        \n","        duplicates.show(20, truncate=False)\n","    else:\n","        print(\"\\nNo duplicate records found!\")\n","    \n","    # 5. Resource Management: Release memory once the audit is finished.\n","    df_cached.unpersist(blocking=True)\n","    \n","    print(\"Record count check complete!\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","session_id":"9b8a09ed-c18f-4da2-b607-66d6efb5db58","normalized_state":"finished","queued_time":"2026-02-01T04:09:25.9095946Z","session_start_time":null,"execution_start_time":"2026-02-01T04:09:46.1652757Z","execution_finish_time":"2026-02-01T04:09:46.4968624Z","parent_msg_id":"83e877e2-e2ab-4a09-8c3b-c904c458fecc"},"text/plain":"StatementMeta(, 9b8a09ed-c18f-4da2-b607-66d6efb5db58, 10, Finished, Available, Finished)"},"metadata":{}}],"execution_count":8,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"bc5f3cb9-9f78-4674-940c-6f54ddd6ed3d"},{"cell_type":"code","source":["# Function to remove specific known anomalies from the geolocation dataset\n","def clean_dirty_data(df):\n","    \"\"\"\n","    Excludes specific records identified as 'dirty data' based on manually \n","    verified zip code and state mismatches.\n","\n","    Args:\n","        df (pyspark.sql.DataFrame): The input geolocation DataFrame.\n","\n","    Returns:\n","        pyspark.sql.DataFrame: A filtered DataFrame with the specified anomalies removed.\n","    \"\"\"\n","\n","    #Clean by removing dirty data - Geolocation\n","\n","    print(\"In clean_dirty_data ...\")\n","\n","    # The filter uses the Tilde (~) as a 'NOT' operator.\n","    # It removes any row where the Zip Code and State combination matches the bad data list.\n","    df = df.filter(\n","        ~(\n","            ((df.geolocation_zip_code_prefix == \"80630\") & (df.geolocation_state == \"SC\")) |\n","            ((df.geolocation_zip_code_prefix == \"72915\") & (df.geolocation_state == \"DF\")) |\n","            ((df.geolocation_zip_code_prefix == \"78557\") & (df.geolocation_state == \"RO\")) |\n","            ((df.geolocation_zip_code_prefix == \"02116\") & (df.geolocation_state == \"RN\")) |\n","            ((df.geolocation_zip_code_prefix == \"23056\") & (df.geolocation_state == \"AC\")) |\n","            ((df.geolocation_zip_code_prefix == \"04011\") & (df.geolocation_state == \"AC\")) |\n","            ((df.geolocation_zip_code_prefix == \"79750\") & (df.geolocation_state == \"RS\")) |\n","            ((df.geolocation_zip_code_prefix == \"21550\") & (df.geolocation_state == \"AC\"))\n","        )\n","    )\n","\n","    print(\"Cleaning script executed ! \")\n","\n","    return df\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"state":"finished","livy_statement_state":"available","session_id":"9b8a09ed-c18f-4da2-b607-66d6efb5db58","normalized_state":"finished","queued_time":"2026-02-01T04:09:26.0898129Z","session_start_time":null,"execution_start_time":"2026-02-01T04:09:46.5001181Z","execution_finish_time":"2026-02-01T04:09:46.8004754Z","parent_msg_id":"4d563d75-4faf-4ae4-b86c-8aa643a03ffa"},"text/plain":"StatementMeta(, 9b8a09ed-c18f-4da2-b607-66d6efb5db58, 11, Finished, Available, Finished)"},"metadata":{}}],"execution_count":9,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"32bbec80-f1cc-46ec-bf1a-97d6a08fdd72"},{"cell_type":"code","source":["# Function to identify and display records missing critical geographic identifiers\n","def check_null_columns(df):\n","    \"\"\"\n","    Scans the dataset for missing values in the primary geographic keys \n","    (Zip Code and State). If nulls are found, it prints the total count \n","    and displays a sample of the affected records.\n","\n","    Args:\n","        df (pyspark.sql.DataFrame): The input geolocation DataFrame.\n","    \"\"\"\n","\n","    print(\"In check_null_columns ...\")\n","    \n","    # 1. Filter logic: Using the 'OR' operator (|) to catch rows missing \n","    # either the zip code prefix or the state code.\n","    null_df = df.filter(\n","            F.col(\"geolocation_zip_code_prefix\").isNull() | \n","            F.col(\"geolocation_state\").isNull()          \n","        )\n","\n","    # 2. Count Check: Determine the volume of incomplete data.\n","    null_count = null_df.count()\n","    print(f\"Records with null columns: {null_count}\")\n","\n","    # 3. Investigation: Only trigger the .show() action if there is \n","    # actual dirty data to inspect, saving compute resources.\n","    if null_count > 0:\n","        # Reuses the filtered logic\n","        null_df.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":12,"statement_ids":[12],"state":"finished","livy_statement_state":"available","session_id":"9b8a09ed-c18f-4da2-b607-66d6efb5db58","normalized_state":"finished","queued_time":"2026-02-01T04:09:26.2761512Z","session_start_time":null,"execution_start_time":"2026-02-01T04:09:46.8036975Z","execution_finish_time":"2026-02-01T04:09:47.1352477Z","parent_msg_id":"0944f042-0944-4e9b-beec-a1455dc7a5dc"},"text/plain":"StatementMeta(, 9b8a09ed-c18f-4da2-b607-66d6efb5db58, 12, Finished, Available, Finished)"},"metadata":{}}],"execution_count":10,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"bb332ea6-74d3-4b2c-b826-6baf253994e0"},{"cell_type":"code","source":["# Function to align zip code prefixes with official municipality names\n","def apply_zipcode_city_standardization(df):\n","    \"\"\"\n","    Standardizes city names for specific zip code prefixes where the raw data\n","    contains district names or variations instead of the official municipality.\n","    Based on official Brazilian CEP (postal code) data alignment.\n","    \n","    Args:\n","        df (pyspark.sql.DataFrame): Input DataFrame containing geolocation keys.\n","    \n","    Returns:\n","        pyspark.sql.DataFrame: DataFrame with corrected city names.\n","    \"\"\"\n","\n","    print(\"In apply_zipcode_city_standardization ...\")\n","    \n","    # Initialize the column reference to track the chain of 'when' conditions\n","    city_col = col(\"geolocation_city\")\n","    \n","    # Dictionary of specific Zip-to-City corrections\n","    # Key: Zip Code Prefix | Value: Official Municipality Name\n","    zipcode_corrections = {\n","        '45936': 'mucuri',\n","        '65935': 'senador la rocque',\n","        '09780': 'sao bernardo do campo',\n","        '13318': 'cabreuva',  # Jacaré is a district of Cabreúva\n","        '13855': 'mogi guacu',\n","        '17970': 'sao joao do pau dalho',\n","        '25936': 'mage',  # Guia de Pacobaíba and Inhomirim are districts of Magé\n","        '27163': 'barra do pirai',\n","        '28950': 'armacao dos buzios',\n","        '28993': 'saquarema',\n","        '35315': 'caratinga',  # Santa Luzia de Caratinga is a district\n","        '36206': 'mantiqueira',\n","        '38295': 'limeira do oeste',\n","        '38749': 'patrocinio',\n","        '42820': 'camacari',  # Monte Gordo is a district\n","        '42841': 'camacari',  # Abrantes is a district\n","        '45816': 'porto seguro',  # Arraial d'Ajuda is a district\n","        '72270': 'brasilia',  # Ceilândia is an administrative region\n","        '85139': 'guarapuava',\n","        '87365': 'quarto centenario',\n","        '01307': 'sao paulo',\n","        '03203': 'sao paulo',\n","        '04004': 'sao paulo',\n","        '04132': 'sao paulo',\n","        '04346': 'sao paulo',\n","        '05026': 'sao paulo',\n","        '05372': 'sao paulo',\n","        '05854': 'sao paulo',\n","        '06050': 'osasco',\n","        '06803': 'embu das artes',\n","        '06804': 'embu das artes',\n","        '06805': 'embu das artes',\n","        '06806': 'embu das artes',\n","        '06807': 'embu das artes',\n","        '06810': 'embu das artes',\n","        '06813': 'embu das artes',\n","        '06814': 'embu das artes',\n","        '06815': 'embu das artes',\n","        '06816': 'embu das artes',\n","        '06817': 'embu das artes',\n","        '06820': 'embu das artes',\n","        '06823': 'embu das artes',\n","        '06824': 'embu das artes',\n","        '06825': 'embu das artes',\n","        '06826': 'embu das artes',\n","        '06833': 'embu das artes',\n","        '06835': 'embu das artes',\n","        '06840': 'embu das artes',\n","        '06843': 'embu das artes',\n","        '06844': 'embu das artes',\n","        '06845': 'embu das artes',\n","        '06846': 'embu das artes',\n","        '06900': 'embu guacu',\n","        '07097': 'guarulhos',\n","        '07141': 'guarulhos',\n","        '07174': 'guarulhos',\n","        '07770': 'cajamar',\n","        '07776': 'cajamar',\n","        '07786': 'cajamar',\n","        '07787': 'cajamar',\n","        '07790': 'cajamar',\n","        '07792': 'cajamar',\n","        '07793': 'cajamar',\n","        '08120': 'sao paulo',\n","        '08543': 'ferraz de vasconcelos',\n","        '08730': 'mogi das cruzes',\n","        '08940': 'biritiba mirim',\n","        '09540': 'sao caetano do sul',\n","        '11610': 'sao sebastiao',\n","        '11612': 'sao sebastiao',\n","        '11619': 'sao sebastiao',\n","        '11621': 'sao sebastiao',\n","        '11623': 'sao sebastiao',\n","        '11626': 'sao sebastiao',\n","        '11628': 'sao sebastiao',\n","        '12140': 'sao luis do paraitinga',\n","        '12249': 'sao jose dos campos',\n","        '13380': 'nova odessa',\n","        '13450': 'santa barbara doeste',\n","        '13451': 'santa barbara doeste',\n","        '13453': 'santa barbara doeste',\n","        '13454': 'santa barbara doeste',\n","        '13455': 'santa barbara doeste',\n","        '13456': 'santa barbara doeste',\n","        '13457': 'santa barbara doeste',\n","        '13458': 'santa barbara doeste',\n","        '13800': 'mogi mirim',\n","        '13801': 'mogi mirim',\n","        '13802': 'mogi mirim',\n","        '13803': 'mogi mirim',\n","        '13805': 'mogi mirim',\n","        '13806': 'mogi mirim',\n","        '13807': 'mogi mirim',\n","        '13808': 'mogi mirim',\n","        '13820': 'jaguariuna',\n","        '13840': 'mogi guacu',\n","        '13841': 'mogi guacu',\n","        '13842': 'mogi guacu',\n","        '13843': 'mogi guacu',\n","        '13844': 'mogi guacu',\n","        '13845': 'mogi guacu',\n","        '13846': 'mogi guacu',\n","        '13847': 'mogi guacu',\n","        '13848': 'mogi guacu',\n","        '13849': 'mogi guacu',\n","        '13910': 'monte alegre do sul',\n","        '14110': 'ribeirao preto',\n","        '14407': 'franca',\n","        '14760': 'pitangueiras',\n","        '15650': 'estrela doeste',\n","        '15720': 'palmeira doeste',\n","        '15735': 'aparecida doeste',\n","        '15780': 'santa rita doeste',\n","        '15785': 'santa clara doeste',\n","        '15953': 'santa adelia',\n","        '17123': 'agudos',\n","        '17220': 'jau',\n","        '17405': 'garca',\n","        '18240': 'angatuba',\n","        '18271': 'tatui',\n","        '18618': 'botucatu',\n","        '18725': 'paranapanema',\n","        '18980': 'chavantes',\n","        '19120': 'presidente prudente',\n","        '19274': 'rosana',\n","        '19845': 'maracai',\n","        '19870': 'florinia',\n","        '19882': 'candido mota',\n","        '21032': 'rio de janeiro',\n","        '21341': 'rio de janeiro',\n","        '22260': 'rio de janeiro',\n","        '23073': 'rio de janeiro',\n","        '23870': 'mangaratiba',\n","        '23880': 'mangaratiba',\n","        '23885': 'mangaratiba',\n","        '23895': 'seropedica',\n","        '23968': 'angra dos reis',\n","        '23970': 'paraty',\n","        '24900': 'marica',\n","        '24913': 'marica',\n","        '24914': 'marica',\n","        '25860': 'paraiba do sul',\n","        '25882': 'sapucaia',\n","        '25887': 'sapucaia',\n","        '25912': 'mage',\n","        '25920': 'mage',\n","        '25930': 'mage',\n","        '25931': 'mage',\n","        '25935': 'mage',\n","        '26520': 'nilopolis',\n","        '26660': 'engenheiro paulo de frontin',\n","        '26910': 'miguel pereira',\n","        '26980': 'paty do alferes',\n","        '27155': 'barra do pirai',\n","        '27165': 'barra do pirai',\n","        '27475': 'rio claro',\n","        '27555': 'resende',\n","        '27598': 'itatiaia',\n","        '27650': 'valenca',\n","        '27655': 'valenca',\n","        '27657': 'valenca',\n","        '27770': 'vassouras',\n","        '27987': 'macae',\n","        '29132': 'viana',\n","        '29187': 'fundao',\n","        '35348': 'pingodagua',\n","        '37200': 'lavras',\n","        '37530': 'brazopolis',\n","        '42850': 'dias davila',\n","        '45195': 'planalto',\n","        '45470': 'jiquirica',\n","        '45625': 'barro preto',\n","        '46835': 'nova redencao',\n","        '47115': 'muquem de sao francisco',\n","        '47220': 'campo alegre de lourdes',\n","        '47310': 'casa nova',\n","        '48355': 'itamira',\n","        '48610': 'gloria',\n","        '54400': 'jaboatao dos guararapes',\n","        '54590': 'cabo de santo agostinho',\n","        '54749': 'sao lourenco da mata',\n","        '55473': 'panelas',\n","        '55485': 'jurema',\n","        '55735': 'bom jardim',\n","        '56440': 'belem do sao francisco',\n","        '56820': 'caraiba',\n","        '56828': 'quixaba',\n","        '57246': 'sao miguel dos campos',\n","        '57258': 'campo alegre',\n","        '57319': 'pau darco',\n","        '59730': 'olhodagua do borges',\n","        '61962': 'maranguape',\n","        '62502': 'itapipoca',\n","        '62597': 'cruz',\n","        '62800': 'aracati',\n","        '62852': 'cascavel',\n","        '63765': 'sucesso',\n","        '65706': 'olho dagua das cunhas',\n","        '65760': 'presidente dutra',\n","        '65943': 'grajau',\n","        '68617': 'cachoeira de piria',\n","        '69555': 'tefe',\n","        '73330': 'brasilia',\n","        '73360': 'brasilia',\n","        '73370': 'brasilia',\n","        '73750': 'planaltina de goias',\n","        '73752': 'planaltina de goias',\n","        '73760': 'sao joao dalianca',\n","        '75260': 'senador canedo',\n","        '75390': 'trindade',\n","        '75570': 'bom jesus de goias',\n","        '75893': 'sao simao',\n","        '75914': 'riverlandia',\n","        '76310': 'rianapolis',\n","        '76385': 'goianesia',\n","        '76840': 'porto velho',\n","        '76842': 'porto velho',\n","        '76846': 'porto velho',\n","        '76847': 'porto velho',\n","        '76850': 'guajara mirim',\n","        '76868': 'machadinho doeste',\n","        '76930': 'alvorada doeste',\n","        '76952': 'alto alegre dos parecis',\n","        '76954': 'alta floresta do oeste',\n","        '76958': 'nova brasilandia doeste',\n","        '76963': 'jiparana',\n","        '76970': 'pimenta bueno',\n","        '76990': 'nova brasilandia doeste',\n","        '78245': 'vila bela da santissima trindade',\n","        '78278': 'lambari doeste',\n","        '78280': 'mirassol doeste',\n","        '78290': 'figueiropolis doeste',\n","        '78402': 'diamantino',\n","        '78678': 'ribeirao cascalheira',\n","        '78816': 'juscimeira',\n","        '79760': 'bataipora',\n","        '81470': 'curitiba',\n","        '83404': 'colombo',\n","        '83810': 'mandirituba',\n","        '85575': 'sao jorge doeste',\n","        '85580': 'itapejara doeste',\n","        '85794': 'capitao leonidas marques',\n","        '85896': 'diamante doeste',\n","        '86818': 'apucarana',\n","        '86819': 'apucarana',\n","        '87145': 'paicandu',\n","        '87214': 'cianorte',\n","        '87395': 'rancho alegre doeste',\n","        '87895': 'terra rica',\n","        '88058': 'florianopolis',\n","        '88061': 'florianopolis',\n","        '88165': 'biguacu',\n","        '88330': 'balneario camboriu',\n","        '88370': 'navegantes',\n","        '88371': 'navegantes',\n","        '88380': 'balneario picarras',\n","        '88509': 'lages',\n","        '88835': 'morro da fumaca',\n","        '88915': 'maracaja',\n","        '89115': 'luiz alves',\n","        '89143': 'ibirama',\n","        '89294': 'campo alegre',\n","        '89610': 'herval doeste',\n","        '91130': 'porto alegre',\n","        '95181': 'farroupilha',\n","        '95272': 'flores da cunha',\n","        '96222': 'rio grande',\n","        '96859': 'santa cruz do sul',\n","        '97538': 'barra do quarai',\n","        '28026': 'campos dos goytacazes',\n","        '28110': 'campos dos goytacazes',\n","        '28140': 'campos dos goytacazes',\n","        '28145': 'campos dos goytacazes',\n","        '28175': 'campos dos goytacazes',\n","        '28333': 'itaperuna',\n","        '28348': 'itaperuna',\n","        '28450': 'cambuci',\n","        '28557': 'sao sebastiao do alto',\n","        '28595': 'itaocara',\n","        '28610': 'nova friburgo',\n","        '28685': 'cachoeiras de macacu',\n","        '28695': 'cachoeiras de macacu',\n","        '28750': 'trajano de moraes',\n","        '28880': 'casimiro de abreu',\n","        '28927': 'cabo frio',\n","        '28980': 'araruama',\n","        '28994': 'saquarema',\n","        '28997': 'saquarema',\n","        '29273': 'domingos martins',\n","        '29278': 'domingos martins',\n","        '29321': 'cachoeiro de itapemirim',\n","        '29338': 'itapemirim',\n","        '29375': 'venda nova do imigrante',\n","        '29660': 'santa teresa',\n","        '29665': 'sao roque do canaa',\n","        '29755': 'pancas',\n","        '29800': 'barra de sao francisco',\n","        '29901': 'linhares',\n","        '29967': 'conceicao da barra',\n","        '31580': 'belo horizonte',\n","        '31610': 'belo horizonte',\n","        '32260': 'contagem',\n","        '34740': 'sabara',\n","        '34950': 'caete',\n","        '35108': 'governador valadares',\n","        '35147': 'naquenanuque',\n","        '35196': 'belo oriente',\n","        '35222': 'itueta',\n","        '35243': 'conselheiro pena',\n","        '35245': 'ferruginha',\n","        '35280': 'itabirinha',\n","        '35362': 'sao pedro dos ferros',\n","        '35365': 'abre campo',\n","        '35367': 'matipo',\n","        '35409': 'ouro preto',\n","        '35410': 'ouro preto',\n","        '35411': 'ouro preto',\n","        '35412': 'ouro preto',\n","        '35413': 'ouro preto',\n","        '35418': 'ouro preto',\n","        '35435': 'rosario do pontal',\n","        '35464': 'brumadinho',\n","        '35541': 'oliveira',\n","        '35672': 'mateus leme',\n","        '35698': 'antunes',\n","        '35905': 'itabira',\n","        '35975': 'barao de cocais',\n","        '36207': 'pinheiro grosso',\n","        '36264': 'vitorinos',\n","        '36315': 'sao joao del rei',\n","        '36490': 'piranga',\n","        '36574': 'vicosa',\n","        '36576': 'vicosa',\n","        '36846': 'tombos',\n","        '36905': 'manhuacu',\n","        '36908': 'manhuacu',\n","        '37136': 'alfenas',\n","        '37556': 'pouso alegre',\n","        '37557': 'pouso alegre',\n","        '37558': 'pouso alegre',\n","        '37559': 'pouso alegre',\n","        '37560': 'pouso alegre',\n","        '37653': 'camanducaia',\n","        '37723': 'botelhos',\n","        '37925': 'piumhi',\n","        '38106': 'uberaba',\n","        '38439': 'martinesia',\n","        '38738': 'brejo bonito',\n","        '38773': 'joao pinheiro',\n","        '38775': 'joao pinheiro',\n","        '38845': 'carmo do paranaiba',\n","        '39120': 'gouveia',\n","        '39398': 'olhos dagua',\n","        '39414': 'montes claros',\n","        '39445': 'janauba',\n","        '39526': 'catuti',\n","        '39602': 'aracuai',\n","        '39809': 'mucuri',\n","        '39862': 'nanuque',\n","        '42835': 'camacari',\n","        '42840': 'camacari',\n","        '43843': 'candeias',\n","        '44590': 'santa terezinha',\n","        '45818': 'porto seguro',\n","        '45928': 'nova vicosa',\n","        '45990': 'teixeira de freitas',\n","        '53900': 'itamaraca',\n","        '54420': 'jaboatao dos guararapes',\n","        '57010': 'maceio',\n","        '57442': 'olho dagua das flores',\n","        '58100': 'campina grande',\n","        '58101': 'campina grande',\n","        '58102': 'campina grande',\n","        '58103': 'campina grande',\n","        '58108': 'campina grande',\n","        '58304': 'santa rita',\n","        '58428': 'campina grande',\n","        '58429': 'campina grande',\n","        '58430': 'campina grande',\n","        '58432': 'campina grande',\n","        '58433': 'campina grande',\n","        '58434': 'campina grande',\n","        '58441': 'campina grande',\n","        '58463': 'santa cecilia',\n","        '59179': 'tibau do sul',\n","        '59570': 'ceara mirim',\n","        '59585': 'sao miguel de touros',\n","        '62600': 'itapaje',\n","        '65370': 'pindare mirim',\n","        '65485': 'itapecuru mirim',\n","        '68129': 'mojui dos campos',\n","        '68275': 'oriximina',\n","        '68447': 'barcarena',\n","        '68448': 'barcarena',\n","        '68516': 'parauapebas',\n","        '68545': 'pau darco',\n","        '68682': 'tomeacu',\n","        '68695': 'tailandia',\n","        '68792': 'santa isabel do para',\n","        '68945': 'pedra branca do amapari',\n","        '69919': 'rio branco',\n","        '69921': 'rio branco',\n","        '70645': 'brasilia',\n","        '70648': 'brasilia',\n","        '70650': 'brasilia',\n","        '70655': 'brasilia',\n","        '70658': 'brasilia',\n","        '70660': 'brasilia',\n","        '70670': 'brasilia',\n","        '70673': 'brasilia',\n","        '70675': 'brasilia',\n","        '71010': 'brasilia',\n","        '71015': 'brasilia',\n","        '71020': 'brasilia',\n","        '71050': 'brasilia',\n","        '71065': 'brasilia',\n","        '71070': 'brasilia',\n","        '71200': 'brasilia',\n","        '71503': 'brasilia',\n","        '71505': 'brasilia',\n","        '71510': 'brasilia',\n","        '71515': 'brasilia',\n","        '71535': 'brasilia',\n","        '71571': 'brasilia',\n","        '71596': 'brasilia',\n","        '71600': 'brasilia',\n","        '71605': 'brasilia',\n","        '71615': 'brasilia',\n","        '71620': 'brasilia',\n","        '71625': 'brasilia',\n","        '71635': 'brasilia',\n","        '71640': 'brasilia',\n","        '71645': 'brasilia',\n","        '71660': 'brasilia',\n","        '71665': 'brasilia',\n","        '71670': 'brasilia',\n","        '71675': 'brasilia',\n","        '71680': 'brasilia',\n","        '71692': 'brasilia',\n","        '71693': 'brasilia',\n","        '71705': 'brasilia',\n","        '71720': 'brasilia',\n","        '71725': 'brasilia',\n","        '71727': 'brasilia',\n","        '71736': 'brasilia',\n","        '71741': 'brasilia',\n","        '71745': 'brasilia',\n","        '71805': 'brasilia',\n","        '71825': 'brasilia',\n","        '71880': 'brasilia',\n","        '71901': 'brasilia',\n","        '71907': 'brasilia',\n","        '71908': 'brasilia',\n","        '71909': 'brasilia',\n","        '71915': 'brasilia',\n","        '71917': 'brasilia',\n","        '71925': 'brasilia',\n","        '71926': 'brasilia',\n","        '71927': 'brasilia',\n","        '71937': 'brasilia',\n","        '71938': 'brasilia',\n","        '71939': 'brasilia',\n","        '71950': 'brasilia',\n","        '71955': 'brasilia',\n","        '72007': 'brasilia',\n","        '72010': 'brasilia',\n","        '72015': 'brasilia',\n","        '72025': 'brasilia',\n","        '72110': 'brasilia',\n","        '72115': 'brasilia',\n","        '72120': 'brasilia',\n","        '72125': 'brasilia',\n","        '72130': 'brasilia',\n","        '72140': 'brasilia',\n","        '72146': 'brasilia',\n","        '72150': 'brasilia',\n","        '72152': 'brasilia',\n","        '72155': 'brasilia',\n","        '72210': 'brasilia',\n","        '72215': 'brasilia',\n","        '72220': 'brasilia',\n","        '72225': 'brasilia',\n","        '72231': 'brasilia',\n","        '72233': 'brasilia',\n","        '72235': 'brasilia',\n","        '72240': 'brasilia',\n","        '72241': 'brasilia',\n","        '72251': 'brasilia',\n","        '72301': 'brasilia',\n","        '72302': 'brasilia',\n","        '72304': 'brasilia',\n","        '72306': 'brasilia',\n","        '72308': 'brasilia',\n","        '72312': 'brasilia',\n","        '72318': 'brasilia',\n","        '72319': 'brasilia',\n","        '72320': 'brasilia',\n","        '72327': 'brasilia',\n","        '72329': 'brasilia',\n","        '72331': 'brasilia',\n","        '72335': 'brasilia',\n","        '72410': 'brasilia',\n","        '72415': 'brasilia',\n","        '72420': 'brasilia',\n","        '72445': 'brasilia',\n","        '72501': 'brasilia',\n","        '72504': 'brasilia',\n","        '72506': 'brasilia',\n","        '72507': 'brasilia',\n","        '72542': 'brasilia',\n","        '72543': 'brasilia',\n","        '72546': 'brasilia',\n","        '72547': 'brasilia',\n","        '72592': 'brasilia',\n","        '72593': 'brasilia',\n","        '72600': 'brasilia',\n","        '72601': 'brasilia',\n","        '72620': 'brasilia',\n","        '72710': 'brasilia',\n","        '72715': 'brasilia',\n","        '72725': 'brasilia',\n","        '72726': 'brasilia',\n","        '73005': 'brasilia',\n","        '73010': 'brasilia',\n","        '73015': 'brasilia',\n","        '73025': 'brasilia',\n","        '73030': 'brasilia',\n","        '73035': 'brasilia',\n","        '73040': 'brasilia',\n","        '73045': 'brasilia',\n","        '73050': 'brasilia',\n","        '73060': 'brasilia',\n","        '73080': 'brasilia',\n","        '73092': 'brasilia',\n","        '73100': 'brasilia',\n","        '73105': 'brasilia',\n","        '73252': 'brasilia'        \n","    }\n","    \n","    # Iteratively build a single 'CASE WHEN' expression.\n","    # This creates a chain: when(zip1, city1).when(zip2, city2)...otherwise(original)\n","    for zipcode, correct_city in zipcode_corrections.items():\n","        city_col = when(\n","            col(\"geolocation_zip_code_prefix\") == zipcode,\n","            correct_city\n","        ).otherwise(city_col)\n","    \n","    df_corrected = df.withColumn(\"geolocation_city\", city_col)\n","    \n","    return df_corrected"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":13,"statement_ids":[13],"state":"finished","livy_statement_state":"available","session_id":"9b8a09ed-c18f-4da2-b607-66d6efb5db58","normalized_state":"finished","queued_time":"2026-02-01T04:09:26.4524221Z","session_start_time":null,"execution_start_time":"2026-02-01T04:09:47.1400319Z","execution_finish_time":"2026-02-01T04:09:47.4973093Z","parent_msg_id":"216542a0-6271-41ce-be93-be9c403b7d26"},"text/plain":"StatementMeta(, 9b8a09ed-c18f-4da2-b607-66d6efb5db58, 13, Finished, Available, Finished)"},"metadata":{}}],"execution_count":11,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0d0b03ff-de12-4cd0-bfa4-e6bbe71c94f4"},{"cell_type":"code","source":["# Function to identify data quality issues where one Zip Code maps to multiple City names\n","def check_city_name_variances(df):\n","    \"\"\"\n","    Detects inconsistency in geographic naming. It identifies zip code prefixes \n","    that are linked to more than one unique city name and displays the conflicting \n","    variations.\n","    \n","    Args:\n","        df (pyspark.sql.DataFrame): The geolocation DataFrame to audit.\n","    \"\"\"\n","\n","    print(\"In check_city_name_variances ...\")\n","    \n","    # 1. Performance Optimization: \n","    # Repartitioning ensures all rows for the same Zip are on the same node.\n","    # Caching prevents reading from the source Lakehouse multiple times.\n","    df_repartitioned = df.repartition(200, \"geolocation_zip_code_prefix\").cache()\n","    \n","    # 2. Step 1: Identification\n","    # Finds only the Zip Codes that have a 'variation_count' greater than 1.\n","    conflicting_zips = df_repartitioned.groupBy(\"geolocation_zip_code_prefix\") \\\n","        .agg(F.countDistinct(\"geolocation_city\").alias(\"variation_count\")) \\\n","        .filter(F.col(\"variation_count\") > 1) \\\n","        .cache()  # Cache this small result for the join\n","    \n","    # Trigger caching by counting conflicts\n","    conflict_count = conflicting_zips.count()\n","    print(f\"Found {conflict_count} zip codes with city name conflicts\")\n","    \n","    # 3. Step 2: Detail Retrieval\n","    # Inner join filters the main data to only show rows that were identified in Step 1.\n","    # collect_set() creates a unique list of the conflicting names.\n","    zip_conflicts = df_repartitioned.join(\n","        conflicting_zips, \n","        \"geolocation_zip_code_prefix\", \n","        \"inner\"\n","    ) \\\n","    .groupBy(\"geolocation_zip_code_prefix\", \"variation_count\") \\\n","    .agg(F.array_sort(F.collect_set(\"geolocation_city\")).alias(\"city_variations\")) \\\n","    .orderBy(F.desc(\"variation_count\")) \\\n","    .limit(50)\n","    \n","    # 4. Result Visualization\n","    print(\"Zip codes with multiple city name variations:\")\n","    zip_conflicts.show(20, truncate=False)\n","    \n","    # 5. Memory Management: \n","    # unpersist() is crucial here to free up RAM for the final load/write steps.\n","    conflicting_zips.unpersist(blocking=True)\n","    df_repartitioned.unpersist(blocking=True)\n","    \n","    print(\"City variance check complete!\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":14,"statement_ids":[14],"state":"finished","livy_statement_state":"available","session_id":"9b8a09ed-c18f-4da2-b607-66d6efb5db58","normalized_state":"finished","queued_time":"2026-02-01T04:09:26.704069Z","session_start_time":null,"execution_start_time":"2026-02-01T04:09:47.5006633Z","execution_finish_time":"2026-02-01T04:09:47.8159396Z","parent_msg_id":"91c06925-6061-441c-a41d-1c5d5ad747ca"},"text/plain":"StatementMeta(, 9b8a09ed-c18f-4da2-b607-66d6efb5db58, 14, Finished, Available, Finished)"},"metadata":{}}],"execution_count":12,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"910ebda2-3e7b-472a-860c-cfbbb37c063a"},{"cell_type":"code","source":["# ==============================================================================\n","# GEOLOCATION SILVER PIPELINE EXECUTION\n","# ==============================================================================\n","from_table_name = 'BronzeLakeHouse.dbo.geolocation_bronze'\n","to_table_name = 'geolocation_silver'\n","\n","# 1. Extraction\n","df = extract_table(from_table_name)\n","\n","# 2. Initial Quality Check & Manual Filtering\n","check_null_columns(df)\n","df = clean_dirty_data(df)\n","\n","# Optimization: Break the 'Lineage' to keep the Spark Query Plan small.\n","# This saves the current state to the checkpoint directory you set in config.\n","df = df.checkpoint()  \n","\n","# 3. Text & Geographic Standardization\n","df = clean_geolocation_city(df)\n","df = apply_zipcode_city_standardization(df)\n","\n","# Optimization: Break lineage again before the heavy aggregation logic.\n","df = df.checkpoint()  # Break again\n","\n","# 4. Post-Cleaning Audit\n","# This confirms if our standardization successfully merged the city variations.\n","check_city_name_variances(df)\n","\n","# 5. Data Consolidation (Aggregation)\n","# Finds the mean Lat/Lng and drops duplicates.\n","df = group_consolidate_data(df)\n","\n","# 6. Final Integrity Audit\n","# Ensures we have a clean, unique set of keys before writing to Silver.\n","check_records_count(df)\n","\n","# 7. Loading\n","load_df_to_delta(df, to_table_name)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":15,"statement_ids":[15],"state":"finished","livy_statement_state":"available","session_id":"9b8a09ed-c18f-4da2-b607-66d6efb5db58","normalized_state":"finished","queued_time":"2026-02-01T04:09:26.9033699Z","session_start_time":null,"execution_start_time":"2026-02-01T04:09:47.8190191Z","execution_finish_time":"2026-02-01T04:12:02.6005914Z","parent_msg_id":"fc4df209-171a-4348-9744-0417d34c0c2f"},"text/plain":"StatementMeta(, 9b8a09ed-c18f-4da2-b607-66d6efb5db58, 15, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["In check_null_columns ...\nRecords with null columns: 0\nIn clean_dirty_data ...\nCleaning script executed ! \nIn clean_geolocation_city ...\nIn apply_zipcode_city_standardization ...\nIn check_city_name_variances ...\nFound 0 zip codes with city name conflicts\nZip codes with multiple city name variations:\n+---------------------------+---------------+---------------+\n|geolocation_zip_code_prefix|variation_count|city_variations|\n+---------------------------+---------------+---------------+\n+---------------------------+---------------+---------------+\n\nCity variance check complete!\nIn group_consolidate_data ...\nIn check_records_count ...\nTotal count: 19015\nDistinct count (composite key): 19015\nDuplicate records: 0\n\nNo duplicate records found!\nRecord count check complete!\nIn load_df_to_delta ...\nTable 'geolocation_silver' loaded successfully !\n"]}],"execution_count":13,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"advisor":{"adviceMetadata":"{\"artifactId\":\"c7f6081b-fea1-498e-bb3d-0405571c0e5e\",\"activityId\":\"9b8a09ed-c18f-4da2-b607-66d6efb5db58\",\"applicationId\":\"application_1769918244361_0001\",\"jobGroupId\":\"15\",\"advices\":{\"warn\":2}}"}},"id":"4b50c8ea-fca9-4106-b778-9cd78c4cb0a7"},{"cell_type":"code","source":["# ==============================================================================\n","# RESOURCE CLEANUP & SESSION TERMINATION\n","# ==============================================================================\n","\n","# Release the final DataFrame from memory\n","df.unpersist()\n","\n","# Clear all remaining cached data from the Spark Catalog\n","spark.catalog.clearCache()\n","\n","# Remove temporary checkpoint files from storage to save space\n","# The 'True' parameter ensures the folder and all its contents are deleted\n","mssparkutils.fs.rm(\"Files/checkpoints/\", True)\n","\n","# Stop the Spark session to release compute resources\n","mssparkutils.session.stop()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":16,"statement_ids":[16],"state":"finished","livy_statement_state":"available","session_id":"9b8a09ed-c18f-4da2-b607-66d6efb5db58","normalized_state":"finished","queued_time":"2026-02-01T04:09:27.1347088Z","session_start_time":null,"execution_start_time":"2026-02-01T04:12:02.6040219Z","execution_finish_time":"2026-02-01T04:12:04.1390572Z","parent_msg_id":"61f55cd4-bcde-4372-8c12-c914bfff2a84"},"text/plain":"StatementMeta(, 9b8a09ed-c18f-4da2-b607-66d6efb5db58, 16, Finished, Available, Finished)"},"metadata":{}}],"execution_count":14,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a98609d6-d52e-4001-b1b2-df5eb74236d1"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"dc1b06fe-c8d2-48ee-9a55-d0149ad78dcd"},{"id":"791a60f4-f8f8-4ea5-9519-0426798180f4"}],"default_lakehouse":"dc1b06fe-c8d2-48ee-9a55-d0149ad78dcd","default_lakehouse_name":"SilverLakeHouse","default_lakehouse_workspace_id":"7d303a82-1fe7-4f4b-82d6-d23015b8c472"}}},"nbformat":4,"nbformat_minor":5}